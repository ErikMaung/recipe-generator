{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e875a119-f17b-4ac6-82d5-bb765a084ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 00:19:33.360237: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "%run Functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2a12dc-7384-4685-aa7f-3e7e11e7f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "raw_data = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82dcd65-9575-4c88-98e0-8503de2e151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the data\n",
    "truncated_texts = truncate(data = raw_data, col_name = 'review', div = 50, min_words = 20, min_sent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd02ba1-19b4-4363-aca3-f6fa93734ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data for modeling\n",
    "texts = preprocess(data = truncated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe7eeb2-d03c-4ae8-af04-d14b4a133397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = tokenize(data = texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c3248f-24b0-4b6a-8295-20ccd6a7905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_data, val_data, test_data = split_data(data = texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d82f36-13d3-41a4-b114-6f26b2f9d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create n-grams\n",
    "train_x, train_y, val_x, val_y, test_x, test_y, total_words, max_sequence_len = input_seq(train = train_data, val = val_data, test = test_data, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d3d414-d62e-43b1-89bf-b2fbc10da161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding and converting to numpy arrays\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = prepare_for_model(train_x, train_y, val_x, val_y, test_x, test_y, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb087dd-c90d-4c19-bb94-4d2df21022c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:  (30684, 165)\n",
      "train_y:  (30684, 7142)\n",
      "val_x:  (3742, 165)\n",
      "val_y:  (3742, 7142)\n",
      "test_x:  (3885, 165)\n",
      "test_y:  (3885, 7142)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x: \", train_x.shape)\n",
    "print(\"train_y: \", train_y.shape)\n",
    "print(\"val_x: \", val_x.shape)\n",
    "print(\"val_y: \", val_y.shape)\n",
    "print(\"test_x: \", test_x.shape)\n",
    "print(\"test_y: \", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103cbfb6-4655-449d-95e0-b3b6b598af4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 165, 100)          714200    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7142)              721342    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1515942 (5.78 MB)\n",
      "Trainable params: 1515942 (5.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make the model\n",
    "model = tf.keras.models.Sequential([\n",
    "        layers.Embedding(total_words, 100, input_length = max_sequence_len-1),\n",
    "        layers.LSTM(100),\n",
    "        layers.Dense(total_words, activation='softmax'),\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d43eb6-503d-46ce-b0e3-52b5824ffcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "959/959 [==============================] - 103s 104ms/step - loss: 7.1027 - accuracy: 0.0509 - val_loss: 7.0013 - val_accuracy: 0.0601\n",
      "Epoch 2/20\n",
      "959/959 [==============================] - 101s 106ms/step - loss: 6.5471 - accuracy: 0.0684 - val_loss: 6.8789 - val_accuracy: 0.0831\n",
      "Epoch 3/20\n",
      "959/959 [==============================] - 98s 103ms/step - loss: 6.1407 - accuracy: 0.0966 - val_loss: 6.8687 - val_accuracy: 0.0997\n",
      "Epoch 4/20\n",
      "959/959 [==============================] - 99s 103ms/step - loss: 5.8039 - accuracy: 0.1136 - val_loss: 6.9233 - val_accuracy: 0.1026\n",
      "Epoch 5/20\n",
      "889/959 [==========================>...] - ETA: 7s - loss: 5.4640 - accuracy: 0.1328"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(patience = 5, monitor = 'loss') # stop training when accuracy doesn't improve\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(train_x, train_y, epochs = 20, validation_data = (val_x, val_y), verbose = 1, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b925352-69bc-412c-ac4c-c087e0cc31e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
